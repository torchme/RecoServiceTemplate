{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HomeWork 3\n",
    "\n",
    "\n",
    "Домашнее задание: максимум 20 баллов\n",
    "\n",
    "1. Побейте метрику на лидерборде map@10 = 0.063 для userKnn модели с семинара (5 баллов)\n",
    "\n",
    "2. Реализуйте эксперименты с кастомной моделю kNN с семинара. Результат - ноутбук(и) (максимум 15 баллов)\n",
    "\n",
    "(Вы можете отрефакторить код из userknn.py по желанию или не трогать его)\n",
    "\n",
    "Что можно сделать в ноутбуке:\n",
    "\n",
    "- придумать, что делать с холодными пользователями в тесте. \n",
    "- Сделайте рекомендации для них (обратите внимание на rectools.models.popular) (3 балла)\n",
    "  - UserPopular\n",
    "  - UserPopularTopCategory\n",
    "  - NewItems\n",
    "- Сделать кол-во рекомендаций равным N, а не меньше N (3 балла)\n",
    "  - Popular\n",
    "  - NewItems\n",
    "  - ?LastTopViewed\n",
    "- Реализовать тюнинг гиперпараметров (например, векторного расстояния или типов kNN моделей (implicit/rectools/...)) и сделать выводы (3 балла)\n",
    "  - реализовать другие варианты ранжированивания айтемов похожих пользователей и сделать выводы (3 балла)\n",
    "  - провести эксперименты с параметрами оффлайн валидации и сделать выводы (3 балла)\n",
    "    - Optuna\n",
    "    - Wandb, ClearML, MetaFlow\n",
    "\n",
    "1. Оберните модель в сервис (максимум 12 баллов)\n",
    "\n",
    "    предпочтительный онлайн вариант: \n",
    "    - обучаете модель в ноутбуке, \n",
    "    - сохраняете обученную модель (pickle, dill), \n",
    "    - при запуске сервиса ее поднимаете и запрашиваете рекомендации \"на лету\" (12 баллов)\n",
    "    или оффлайн вариант: \n",
    "    - предварительно посчитайте рекомендации для всех пользователей\n",
    "    - сохраните и запрашивайте их (6 баллов)\n",
    "\n",
    "Хороший pull request - это:  \n",
    "    - наличие описания (в идеале что сделано - по пунктам)  \n",
    "    - код по стандарту PEP8  \n",
    "    - легкая читаемость и воспроизводимость кода  \n",
    "    - комментарии и объяснения. В ipynb пользуйтесь силой маркдауна. В скриптах пишите комментарии и докстринг.  \n",
    "    - обоснование схемы валидации  \n",
    "    - анализ метрики качества  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#!pip install rectools\n",
    "#!pip install seaborn\n",
    "#!pip install pyarrow\n",
    "# !pip install Jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = pd.read_csv(\n",
    "    \"../data/interactions.csv\",\n",
    ")\n",
    "\n",
    "items = pd.read_csv(\n",
    "    '../data/items.csv',\n",
    ")\n",
    "\n",
    "# users = pd.read_csv(\n",
    "#     '../data/users.csv',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>last_watch_dt</th>\n",
       "      <th>total_dur</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>4250</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>8317</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>656683</td>\n",
       "      <td>7107</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id last_watch_dt  total_dur  watched_pct\n",
       "0   176549     9506    2021-05-11       4250         72.0\n",
       "1   699317     1659    2021-05-29       8317        100.0\n",
       "2   656683     7107    2021-05-09         10          0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = inter.rename(columns={\"last_watch_dt\": \"datetime\"})\n",
    "\n",
    "inter[\"datetime\"] = pd.to_datetime(inter[\"datetime\"])\n",
    "\n",
    "inter[\"weight\"] = inter[\"total_dur\"] * inter[\"watched_pct\"]\n",
    "# inter['weight'] = np.where(inter['watched_pct'] > 25, 1, 0) * inter['total_dur']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kartushov/pet_projects/itmo/itmo.recsys/RecoServiceTemplate/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/kartushov/pet_projects/itmo/itmo.recsys/RecoServiceTemplate/.venv/lib/python3.10/site-packages/implicit/gpu/__init__.py:13: UserWarning: CUDA extension is built, but disabling GPU support because of 'Cuda Error: no CUDA-capable device is detected (/project/./implicit/gpu/utils.h:71)'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from rectools.metrics import (\n",
    "    Precision,\n",
    "    Recall,\n",
    "    NDCG,\n",
    "    MAP,\n",
    "    Serendipity,\n",
    "    MeanInvUserFreq,\n",
    "    calc_metrics,\n",
    ")\n",
    "\n",
    "from implicit.nearest_neighbours import TFIDFRecommender\n",
    "from rectools.models import RandomModel, PopularModel, PopularInCategoryModel, ImplicitItemKNNWrapperModel\n",
    "from rectools import Columns\n",
    "from rectools.model_selection.time_split import TimeRangeSplitter\n",
    "from rectools.dataset import Interactions, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "\n",
    "n_splits = 3\n",
    "\n",
    "splitter = TimeRangeSplitter(\n",
    "    test_size=\"14D\",\n",
    "    n_splits=n_splits,\n",
    "    filter_already_seen=True,\n",
    "    filter_cold_items=True,\n",
    "    filter_cold_users=True,\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"TDIDF\": TFIDFRecommender(K=K),\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"MAPTop-1\": MAP(k=1),\n",
    "    \"MAPTop-5\": MAP(k=5),\n",
    "    \"MAPTop-10\": MAP(k=10),\n",
    "    \"NDCG@1\": NDCG(k=1),\n",
    "    \"NDCG@5\": NDCG(k=5),\n",
    "    \"NDCG@10\": NDCG(k=10),\n",
    "    \"Precision@1\": Precision(k=1),\n",
    "    \"Precision@5\": Precision(k=5),\n",
    "    \"Precision@10\": Precision(k=10),\n",
    "    \"Recall@1\": Recall(k=1),\n",
    "    \"Recall@5\": Recall(k=5),\n",
    "    \"Recall@10\": Recall(k=10),\n",
    "    \"Novelty@1\": MeanInvUserFreq(k=1),\n",
    "    \"Novelty@5\": MeanInvUserFreq(k=5),\n",
    "    \"Novelty@10\": MeanInvUserFreq(k=10),\n",
    "    \"Serendipity\": Serendipity(k=1),\n",
    "    \"Serendipity\": Serendipity(k=5),\n",
    "    \"Serendipity\": Serendipity(k=10),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class RecSysModule:\n",
    "    def __init__(\n",
    "        self, model_dict: dict = None, metrics_dict: dict = None, splitter: TimeRangeSplitter = None, k: int = 10\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the RecSysModule object.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_dict : dict, optional\n",
    "            Dictionary containing models, by default None\n",
    "        metrics_dict : dict, optional\n",
    "            Dictionary containing metrics, by default None\n",
    "        splitter : TimeRangeSplitter, optional\n",
    "            TimeRangeSplitter object for splitting data, by default None\n",
    "        k : int, optional\n",
    "            Value of 'k' for top-k recommendations, by default 10\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If splitter is not provided.\n",
    "        ValueError\n",
    "            If metrics_dict is not provided.\n",
    "        ValueError\n",
    "            If model_dict is not provided.\n",
    "        ValueError\n",
    "            If no metrics are provided.\n",
    "        ValueError\n",
    "            If no models are provided.\n",
    "        ValueError\n",
    "            If k is negative.\n",
    "        \"\"\"\n",
    "        if splitter is None:\n",
    "            raise ValueError(\"Please provide splitter\")\n",
    "        if metrics_dict is None:\n",
    "            raise ValueError(\"Please provide metrics_dict\")\n",
    "        if model_dict is None:\n",
    "            raise ValueError(\"Please provide model_dict\")\n",
    "        if len(metrics_dict) == 0:\n",
    "            raise ValueError(\"Please provide at least one metric\")\n",
    "        if len(model_dict) == 0:\n",
    "            raise ValueError(\"Please provide at least one model\")\n",
    "        if k < 0:\n",
    "            raise ValueError(\"k cannot be negative\")\n",
    "\n",
    "        self.model_dict = model_dict\n",
    "        self.metrics_dict = metrics_dict\n",
    "        self.splitter = splitter\n",
    "        self.k = k\n",
    "\n",
    "\n",
    "    def fold_iterator(self, dataframe: pd.DataFrame, treshold=5):        \n",
    "        count_views_items = dataframe.groupby('user_id')['item_id'].count()\n",
    "        train_ids = list(count_views_items[count_views_items > treshold].index)\n",
    "        test_ids = list(count_views_items[count_views_items <= treshold].index)\n",
    "\n",
    "        test_ids = [user_id for user_id in test_ids if user_id in train_ids]\n",
    "\n",
    "        return train_ids, test_ids\n",
    "\n",
    "\n",
    "    def evaluate(self, interaction: pd.DataFrame) -> pd.DataFrame:\n",
    "        results = []\n",
    "        \n",
    "        fold_iterator = splitter.split(interaction, collect_fold_stats=True) \n",
    "        for i_fold, (train_ids, test_ids, fold_info) in enumerate(fold_iterator):\n",
    "            print(f\"\\n==================== Fold {i_fold}\")\n",
    "            train = interaction.df.iloc[train_ids].copy()\n",
    "            test = interaction.df.iloc[test_ids][Columns.UserItem].copy()\n",
    "            catalog = train[Columns.Item].unique()\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            test_users = np.unique(test[Columns.User])\n",
    "\n",
    "            for model_name, model in models.items():\n",
    "                userknn_model = UserKnn(model=model, N_users=50)\n",
    "                userknn_model.fit(train)\n",
    "                model.fit(dataset)\n",
    "                recos = userknn_model.predict(test)   \n",
    "                with open(f'../models/{model_name}_{i_fold}.pickle', 'wb') as f:\n",
    "                    pickle.dump(model, f)\n",
    "\n",
    "                recos = model.recommend(\n",
    "                    users=test_users,\n",
    "                    dataset=dataset,\n",
    "                    k=self.k,\n",
    "                    filter_viewed=True,\n",
    "                )\n",
    "\n",
    "                metric_values = calc_metrics(\n",
    "                        metrics,\n",
    "                        reco=recos,\n",
    "                        interactions=test,\n",
    "                        prev_interactions=train,\n",
    "                        catalog=catalog,\n",
    "                    )\n",
    "                end_time = time.time()\n",
    "                evaluation_time = end_time - start_time\n",
    "\n",
    "                res = {\"model\": model_name, \"evaluation_time\": evaluation_time}\n",
    "                res.update(metric_values)\n",
    "\n",
    "        self.metrics_result = results\n",
    "\n",
    "\n",
    "    def visualize_results(self):\n",
    "            pivot_results = pd.DataFrame(self.metrics_result).drop(columns=\"fold\").groupby([\"model\"], sort=False).agg([\"mean\", \"std\"])\n",
    "            mean_metric_subset = [(metric, agg) for metric, agg in pivot_results.columns if agg == 'mean']\n",
    "            return (\n",
    "                pivot_results.style\n",
    "                .highlight_min(subset=mean_metric_subset, color='lightcoral', axis=0)\n",
    "                .highlight_max(subset=mean_metric_subset, color='lightgreen', axis=0)\n",
    "            )\n",
    "\n",
    "\n",
    "    def visualize_analysis(self, model, dataset, user_ids, item_data):\n",
    "        recos = model.predict(item_data)\n",
    "        recos = recos[recos[Columns.User].isin(user_ids)]\n",
    "        recos = recos.merge(item_data, on=[Columns.Item], how='left')[['title', 'genres', Columns.User, Columns.Item]]\n",
    "        \n",
    "        history = dataset.interactions.df\n",
    "        history = history[history[Columns.User].isin(user_ids)]\n",
    "        history = history.merge(item_data, on=[Columns.Item], how='left')[['title', 'genres', Columns.User, Columns.Item]]\n",
    "\n",
    "        for user in user_ids:\n",
    "            print(f\"User {user} history:\")\n",
    "            history_items = history[Columns.Item].unique()\n",
    "            print(f\"Total count views user: {history[history[Columns.User] == user][Columns.Item].nunique()}\")\n",
    "            for item in history_items:\n",
    "                _his_item_dataset = dataset.interactions.df\n",
    "                item_title = history[history[Columns.Item] == item]['title'].values[0]\n",
    "                # unique equal count cuz 1 user ~ 1 item in this set\n",
    "                item_unviews = _his_item_dataset[_his_item_dataset[Columns.Item] == item][Columns.User].nunique()\n",
    "                print(f\"{item_title} | total views: {item_unviews}\")\n",
    "            display(history[history[Columns.User] == user])\n",
    "            print()\n",
    "            print(f\"User {user} recommendations:\")\n",
    "            display(recos[recos[Columns.User] == user])\n",
    "            print()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = Interactions(inter)\n",
    "\n",
    "recsys = RecSysModule(\n",
    "    model_dict=models,\n",
    "    metrics_dict=metrics,\n",
    "    splitter=splitter,\n",
    "    k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT/PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>total_dur</th>\n",
       "      <th>watched_pct</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>4250</td>\n",
       "      <td>72.0</td>\n",
       "      <td>306000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>8317</td>\n",
       "      <td>100.0</td>\n",
       "      <td>831700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>656683</td>\n",
       "      <td>7107</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864613</td>\n",
       "      <td>7638</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>14483</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1448300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>964868</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>6725</td>\n",
       "      <td>100.0</td>\n",
       "      <td>672500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id   datetime  total_dur  watched_pct     weight\n",
       "0   176549     9506 2021-05-11       4250         72.0   306000.0\n",
       "1   699317     1659 2021-05-29       8317        100.0   831700.0\n",
       "2   656683     7107 2021-05-09         10          0.0        0.0\n",
       "3   864613     7638 2021-07-05      14483        100.0  1448300.0\n",
       "4   964868     9506 2021-04-30       6725        100.0   672500.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = TFIDFRecommender(K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = interactions.df\n",
    "dataset = Dataset.construct(\n",
    "    interactions_df=df_train,\n",
    "    user_features_df=None,\n",
    "    item_features_df=None,\n",
    ")\n",
    "catalog = df_train[Columns.Item].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7401/962179 [02:21<5:03:11, 52.49it/s]\n"
     ]
    }
   ],
   "source": [
    "tfidf_model.fit(df_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/TFIDF_0.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mload(\u001b[43mtfidf_model\u001b[49m, f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfidf_model' is not defined"
     ]
    }
   ],
   "source": [
    "with open(f'../models/TFIDF.pickle', 'wb') as f:\n",
    "    pickle.load(tfidf_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TFIDFRecommender' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tfidf_recos \u001b[38;5;241m=\u001b[39m \u001b[43muserknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(df_train)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TFIDFRecommender' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "tfidf_recos = userknn.predict(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_recos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtfidf_recos\u001b[49m\u001b[38;5;241m.\u001b[39mto_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/tfidf.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfidf_recos' is not defined"
     ]
    }
   ],
   "source": [
    "tfidf_recos.to_parquet('data/tfidf.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_recos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67b535036947e74c085a4aadcefc9f79258af3bc3b204eef7c6c9c0865dc5f6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
