{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92954921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "debc4873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Documents/itmo_recsys/Lecture 5. Neural networks/venv_lecture5/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, clear_output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd931e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "843b139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = pd.read_csv('interactions_processed.csv')\n",
    "users_df = pd.read_csv('users_processed.csv')\n",
    "items_df = pd.read_csv('items_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85049f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>last_watch_dt</th>\n",
       "      <th>total_dur</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>4250</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>8317</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>656683</td>\n",
       "      <td>7107</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864613</td>\n",
       "      <td>7638</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>14483</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>964868</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>6725</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id last_watch_dt  total_dur  watched_pct\n",
       "0   176549     9506    2021-05-11       4250           72\n",
       "1   699317     1659    2021-05-29       8317          100\n",
       "2   656683     7107    2021-05-09         10            0\n",
       "3   864613     7638    2021-07-05      14483          100\n",
       "4   964868     9506    2021-04-30       6725          100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fbac8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = interactions_df[interactions_df['last_watch_dt'] < '2021-04-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efe98dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263874, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78342a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# users: 86614\n",
      "# users with at least 5 interactions: 14563\n"
     ]
    }
   ],
   "source": [
    "users_interactions_count_df = interactions_df.groupby(['user_id', 'item_id']).size().groupby('user_id').size()\n",
    "print('# users: %d' % len(users_interactions_count_df))\n",
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['user_id']]\n",
    "print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd0d31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of interactions: 263874\n",
      "# of interactions from users with at least 5 interactions: 142670\n"
     ]
    }
   ],
   "source": [
    "print('# of interactions: %d' % len(interactions_df))\n",
    "interactions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df, \n",
    "               how = 'right',\n",
    "               left_on = 'user_id',\n",
    "               right_on = 'user_id')\n",
    "print('# of interactions from users with at least 5 interactions: %d' % len(interactions_from_selected_users_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b46ee003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2df43577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique user/item interactions: 142670\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>849</td>\n",
       "      <td>6.375039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>4345</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>10283</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>12261</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>15997</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>952</td>\n",
       "      <td>6.044394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>4382</td>\n",
       "      <td>4.954196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>4807</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>10436</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>12132</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  watched_pct\n",
       "0       21      849     6.375039\n",
       "1       21     4345     6.658211\n",
       "2       21    10283     6.658211\n",
       "3       21    12261     6.658211\n",
       "4       21    15997     6.658211\n",
       "5       32      952     6.044394\n",
       "6       32     4382     4.954196\n",
       "7       32     4807     6.658211\n",
       "8       32    10436     6.658211\n",
       "9       32    12132     6.658211"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "    \n",
    "interactions_full_df = interactions_from_selected_users_df \\\n",
    "                    .groupby(['user_id', 'item_id'])['watched_pct'].sum() \\\n",
    "                    .apply(smooth_user_preference).reset_index()\n",
    "print('# of unique user/item interactions: %d' % len(interactions_full_df))\n",
    "interactions_full_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "039e1442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# interactions on Train set: 114136\n",
      "# interactions on Test set: 28534\n"
     ]
    }
   ],
   "source": [
    "interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n",
    "                                   stratify=interactions_full_df['user_id'], \n",
    "                                   test_size=0.20,\n",
    "                                   random_state=42)\n",
    "\n",
    "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
    "print('# interactions on Test set: %d' % len(interactions_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b38dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Indexing by personId to speed up the searches during evaluation\n",
    "interactions_full_indexed_df = interactions_full_df.set_index('user_id')\n",
    "interactions_train_indexed_df = interactions_train_df.set_index('user_id')\n",
    "interactions_test_indexed_df = interactions_test_df.set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbb9a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_interacted(person_id, interactions_df):\n",
    "    # Get the user's data and merge in the movie information.\n",
    "    interacted_items = interactions_df.loc[person_id]['item_id']\n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03042d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top-N accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "\n",
    "class ModelEvaluator:\n",
    "\n",
    "\n",
    "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n",
    "        interacted_items = get_items_interacted(person_id, interactions_full_indexed_df)\n",
    "        all_items = set(articles_df['item_id'])\n",
    "        non_interacted_items = all_items - interacted_items\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
    "        return set(non_interacted_items_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):        \n",
    "            try:\n",
    "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "            except:\n",
    "                index = -1\n",
    "            hit = int(index in range(0, topn))\n",
    "            return hit, index\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id):\n",
    "        #Getting the items in test set\n",
    "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
    "        if type(interacted_values_testset['item_id']) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset['item_id'])\n",
    "        else:\n",
    "            person_interacted_items_testset = set([int(interacted_values_testset['item_id'])])  \n",
    "        interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "\n",
    "        #Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(person_id, \n",
    "                                               items_to_ignore=get_items_interacted(person_id, \n",
    "                                                                                    interactions_train_indexed_df), \n",
    "                                               topn=10000000000)\n",
    "\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        #For each item the user has interacted in test set\n",
    "        for item_id in person_interacted_items_testset:\n",
    "            #Getting a random sample (100) items the user has not interacted \n",
    "            #(to represent items that are assumed to be no relevant to the user)\n",
    "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, \n",
    "                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n",
    "                                                                          seed=item_id%(2**32))\n",
    "\n",
    "            #Combining the current interacted item with the 100 random items\n",
    "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df['item_id'].isin(items_to_filter_recs)]                    \n",
    "            valid_recs = valid_recs_df['item_id'].values\n",
    "            #Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n",
    "        #when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "        person_metrics = {'hits@5_count':hits_at_5_count, \n",
    "                          'hits@10_count':hits_at_10_count, \n",
    "                          'interacted_count': interacted_items_count_testset,\n",
    "                          'recall@5': recall_at_5,\n",
    "                          'recall@10': recall_at_10}\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        #print('Running evaluation for users')\n",
    "        people_metrics = []\n",
    "        for idx, person_id in enumerate(tqdm(list(interactions_test_indexed_df.index.unique().values))):\n",
    "            #if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d users processed' % idx)\n",
    "            person_metrics = self.evaluate_model_for_user(model, person_id)  \n",
    "            person_metrics['user_id'] = person_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print('%d users processed' % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics) \\\n",
    "                            .sort_values('interacted_count', ascending=False)\n",
    "        \n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        \n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}    \n",
    "        return global_metrics, detailed_results_df\n",
    "    \n",
    "model_evaluator = ModelEvaluator()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c56b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9039ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constants\n",
    "SEED = 42 # random seed for reproducibility\n",
    "LR = 1e-3 # learning rate, controls the speed of the training\n",
    "WEIGHT_DECAY = 0.01 # lambda for L2 reg. ()\n",
    "NUM_EPOCHS = 200 # num training epochs (how many times each instance will be processed)\n",
    "GAMMA = 0.9995 # learning rate scheduler parameter\n",
    "BATCH_SIZE = 3000 # training batch size\n",
    "EVAL_BATCH_SIZE = 3000 # evaluation batch size.\n",
    "DEVICE = 'cuda' #'cuda' # device to make the calculations on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b47f52ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/04/yk13n_yx59b89hf91m6vd3r40000gn/T/ipykernel_35134/3875440146.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  total_df = interactions_train_df.append(interactions_test_indexed_df.reset_index())\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_df = interactions_train_df.append(interactions_test_indexed_df.reset_index())\n",
    "total_df['user_id'], users_keys = total_df.user_id.factorize()\n",
    "total_df['item_id'], items_keys = total_df.item_id.factorize()\n",
    "\n",
    "train_encoded = total_df.iloc[:len(interactions_train_df)].values\n",
    "test_encoded = total_df.iloc[len(interactions_train_df):].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27e538cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "shape = [int(total_df['user_id'].max()+1), int(total_df['item_id'].max()+1)]\n",
    "X_train = csr_matrix((train_encoded[:, 2], (train_encoded[:, 0], train_encoded[:, 1])), shape=shape).toarray()\n",
    "X_test = csr_matrix((test_encoded[:, 2], (test_encoded[:, 0], test_encoded[:, 1])), shape=shape).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89cc28b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the DataObject, which must return an element (features vector x and target value y)\n",
    "# for a given idx. This class must also have a length atribute\n",
    "class UserOrientedDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        super().__init__() # to initialize the parent class\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.len = len(X)\n",
    "\n",
    "    def __len__(self): # We use __func__ for implementing in-built python functions\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ee1dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize DataLoaders - objects, which sample instances from DataObject-s\n",
    "train_dl = DataLoader(\n",
    "    UserOrientedDataset(X_train),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    UserOrientedDataset(X_test),\n",
    "    batch_size = EVAL_BATCH_SIZE,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "dls = {'train': train_dl, 'test': test_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27054192",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_and_out_features = 8287):\n",
    "        super().__init__()\n",
    "        self.in_and_out_features = in_and_out_features\n",
    "        self.hidden_size = 500\n",
    "\n",
    "        self.sequential = nn.Sequential( # NN architecure, where the modules modify the data sequentially\n",
    "            nn.Linear(in_and_out_features, self.hidden_size), # Linear transformation\n",
    "            nn.ReLU(), # Activation function\n",
    "            nn.Linear(self.hidden_size, in_and_out_features) # Another Linear transformation\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # In the forward function, you define how your model runs, from input to output \n",
    "        x = self.sequential(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c95f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(SEED) # Fix random seed to have reproducible weights of model layers\n",
    "\n",
    "model = Model()\n",
    "#model.to(DEVICE)\n",
    "\n",
    "# Initialize GD method, which will update the weights of the model\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "# Initialize learning rate scheduler, which will decrease LR according to some rule\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=GAMMA)\n",
    "\n",
    "def rmse_for_sparse(x_pred, x_true):\n",
    "    mask = (x_true > 0)\n",
    "    sq_diff = (x_pred * mask - x_true) ** 2\n",
    "    mse = sq_diff.sum() / mask.sum()\n",
    "    return mse ** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9cdaf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.315015</td>\n",
       "      <td>2.295504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.191636</td>\n",
       "      <td>2.224912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Train RMSE  Test RMSE\n",
       "0      0    2.315015   2.295504\n",
       "1      1    2.191636   2.224912"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "metrics_dict = {\n",
    "    \"Epoch\": [],\n",
    "    \"Train RMSE\": [],\n",
    "    \"Test RMSE\": [],\n",
    "}\n",
    "\n",
    "# Train loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    metrics_dict[\"Epoch\"].append(epoch)\n",
    "    for stage in ['train', 'test']:\n",
    "        with torch.set_grad_enabled(stage == 'train'): # Whether to start building a graph for a backward pass\n",
    "            if stage == 'train':\n",
    "                model.train() # Enable some \"special\" layers (will speak about later)\n",
    "            else:\n",
    "                model.eval() # Disable some \"special\" layers (will speak about later)\n",
    "\n",
    "            loss_at_stage = 0 \n",
    "            for batch in dls[stage]:\n",
    "                #batch = batch.to(DEVICE)\n",
    "                x_pred = model(batch) # forward pass: model(x_batch) -> calls forward()\n",
    "                loss = rmse_for_sparse(x_pred, batch) # Â¡Important! y_pred is always the first arg\n",
    "                if stage == \"train\":\n",
    "                    loss.backward() # Calculate the gradients of all the parameters wrt loss\n",
    "                    optimizer.step() # Update the parameters\n",
    "                    scheduler.step()\n",
    "                    optimizer.zero_grad() # Zero the saved gradient\n",
    "                loss_at_stage += loss.item() * len(batch)\n",
    "            rmse_at_stage = (loss_at_stage / len(dls[stage].dataset)) ** (1/2)\n",
    "            metrics_dict[f\"{stage.title()} RMSE\"].append(rmse_at_stage)\n",
    "            \n",
    "    if (epoch == NUM_EPOCHS - 1) or epoch % 10 == 9:\n",
    "        clear_output(wait=True)\n",
    "        display(pd.DataFrame(metrics_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9bf9546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5702,  0.3948,  0.6736,  ..., -0.0064,  0.0077,  0.0885],\n",
       "        [ 0.0358,  0.0667,  0.0340,  ...,  0.0068,  0.0364,  0.0252],\n",
       "        [ 0.1653,  0.1372,  0.1488,  ..., -0.0698,  0.0321,  0.0593],\n",
       "        ...,\n",
       "        [ 0.0778,  0.1044,  0.0832,  ..., -0.0043,  0.0202,  0.0331],\n",
       "        [ 0.1636,  0.1581,  0.1798,  ..., -0.0055,  0.0379,  0.0274],\n",
       "        [ 0.1760,  0.1519,  0.1613,  ...,  0.0301,  0.0223,  0.0508]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_pred = model(torch.Tensor(X_test))\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bca32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AERecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Autoencoder'\n",
    "    \n",
    "    def __init__(self, X_preds, X_train_and_val, X_test):\n",
    "\n",
    "        self.X_preds = X_preds.cpu().detach().numpy()\n",
    "        self.X_train_and_val = X_train_and_val\n",
    "        self.X_test = X_test\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def recommend_items(self, user_id, items_to_select_idx, topn=10, verbose=False):\n",
    "        user_preds = self.X_preds[user_id][items_to_select_idx]\n",
    "        items_idx = items_to_select_idx[np.argsort(-user_preds)[:topn]]\n",
    "\n",
    "        # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
    "        return items_idx\n",
    "\n",
    "    def evaluate(self, size=100):\n",
    "\n",
    "        X_total = self.X_train_and_val + self.X_test\n",
    "\n",
    "        true_5 = []\n",
    "        true_10 = []\n",
    "\n",
    "        for user_id in range(len(X_test)):\n",
    "            non_zero = np.argwhere(self.X_test[user_id] > 0).ravel()\n",
    "            all_nonzero = np.argwhere(X_total[user_id] > 0).ravel()\n",
    "            select_from = np.setdiff1d(np.arange(X_total.shape[1]), all_nonzero)\n",
    "\n",
    "            for non_zero_idx in non_zero:\n",
    "                random_non_interacted_100_items = np.random.choice(select_from, size=20, replace=False)\n",
    "                preds = self.recommend_items(user_id, np.append(random_non_interacted_100_items, non_zero_idx), topn=10)\n",
    "                true_5.append(non_zero_idx in preds[:5])\n",
    "                true_10.append(non_zero_idx in preds)\n",
    "\n",
    "        return {\"recall@5\": np.mean(true_5), \"recall@10\": np.mean(true_10)}\n",
    "    \n",
    "ae_recommender_model = AERecommender(X_pred, X_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d846334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@5': 0.7822169346738569, 'recall@10': 0.9264044779466976}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_global_metrics = ae_recommender_model.evaluate()\n",
    "ae_global_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_lecture5)",
   "language": "python",
   "name": "venv_lecture5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
